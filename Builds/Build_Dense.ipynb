{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "\n",
    "MAX_SEQ_LENGTH = 40\n",
    "NUM_FEATURES = 2048\n",
    "\n",
    "INDEX = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 80\n",
      "Total videos for testing: 20\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"video list/train.csv\")\n",
    "test_df = pd.read_csv(\"video list/test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "#train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (580, 40, 2048)\n",
      "Frame label in train set: (580, 1)\n",
      "Frame features in test set: (141, 40, 2048)\n",
      "Frame label in test set: (141, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(f\"Index{INDEX}/_features/train_data.npy\")\n",
    "train_labels = np.load(f\"Index{INDEX}/_features/train_labels.npy\")\n",
    "\n",
    "test_data = np.load(f\"Index{INDEX}/_features/test_data.npy\")\n",
    "test_labels = np.load(f\"Index{INDEX}/_features/test_labels.npy\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data.shape}\")\n",
    "print(f\"Frame label in train set: {train_labels.shape}\")\n",
    "\n",
    "print(f\"Frame features in test set: {test_data.shape}\")\n",
    "print(f\"Frame label in test set: {test_labels.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (580, 1)\n",
      "Frame features in test set: (141, 1)\n"
     ]
    }
   ],
   "source": [
    "column = train_labels[:, 0]\n",
    "column[column < 3] = 0\n",
    "column[column >= 3] = 1\n",
    "\n",
    "column = test_labels[:, 0]\n",
    "column[column < 3] = 0\n",
    "column[column >= 3] = 1\n",
    "\n",
    "print(f\"Frame features in train set: {train_labels.shape}\")\n",
    "print(f\"Frame features in test set: {test_labels.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Número 0.0: 38 veces, 6.551724137931035\n",
      "Número 1.0: 77 veces, 13.275862068965516\n",
      "Número 2.0: 29 veces, 5.0\n",
      "Número 3.0: 436 veces, 75.17241379310344\n",
      "Test\n",
      "Número 0.0: 14 veces, 9.929078014184398\n",
      "Número 1.0: 26 veces, 18.439716312056735\n",
      "Número 2.0: 13 veces, 9.219858156028367\n",
      "Número 3.0: 88 veces, 62.4113475177305\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Contar(tensor):\n",
    "    unique_values, counts = np.unique(tensor, return_counts=True)\n",
    "    totalSum = np.sum(counts)\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        print(f\"Número {value}: {count} veces, {(count / totalSum) * 100}\")\n",
    "\n",
    "print(f\"Train\")\n",
    "Contar(train_labels[:, 0])\n",
    "\n",
    "print(f\"Test\")\n",
    "Contar(test_labels[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reshape\n",
      "a 580\n",
      "b 40\n",
      "c 2048\n",
      "(580, 40, 2048)\n",
      "(580, 1)\n",
      "\n",
      "(23200, 2048)\n",
      "(23200, 1)\n",
      "\n",
      "Reshape\n",
      "a 141\n",
      "b 40\n",
      "c 2048\n",
      "(141, 40, 2048)\n",
      "(141, 1)\n",
      "\n",
      "(5640, 2048)\n",
      "(5640, 1)\n"
     ]
    }
   ],
   "source": [
    "#train__data = np.reshape(train_data, (a * b, c))\n",
    "def Reshape(data, labels):\n",
    "    a, b, c = data.shape\n",
    "    print()\n",
    "    print(\"Reshape\")\n",
    "    print(f\"a {a}\")\n",
    "    print(f\"b {b}\")\n",
    "    print(f\"c {c}\")\n",
    "\n",
    "    data_ = np.zeros((a * b, c))\n",
    "    labels_ = np.zeros((a * b, 1))\n",
    "\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            data_[i * j, : ] = data[i, j, :]\n",
    "            labels_[i * j, :] = labels[i, :]\n",
    "\n",
    "    print(data.shape)\n",
    "    print(labels.shape)\n",
    "    print()\n",
    "    print(data_.shape)\n",
    "    print(labels_.shape)\n",
    "\n",
    "    return data_, labels_\n",
    "\n",
    "train__data, train__labels = Reshape(train_data, train_labels)\n",
    "test__data, test__labels = Reshape(test_data, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index15\n",
      "(141, 40, 2048)\n",
      "177/177 [==============================] - 1s 2ms/step - loss: 0.9990 - accuracy: 0.8473\n",
      "Test accuracy: 84.73%\n",
      "0.9989914298057556\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(NUM_FEATURES,)),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(len(np.unique(train_df[\"Target\"])), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Imprimir un resumen del modelo\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = f\"Index{INDEX}/_model/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_model()\n",
    "    #history = seq_model.fit( train__data, train__labels, validation_split=0.3, epochs=EPOCHS, callbacks=[checkpoint],)\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate(test__data, test__labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    return seq_model\n",
    "\n",
    "print(f\"Index{INDEX}\")\n",
    "print(test_data.shape)\n",
    "sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "[0. 1. 2. 3.]\n",
      "[ 38  77  29 436]\n",
      "580\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "y_pred = sequence_model.predict(test__data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calcular el test accuracy general\n",
    "_, test_accuracy = sequence_model.evaluate(test__data, test__labels, verbose=0)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_accuracy * 100))\n",
    "\n",
    "# Obtener el classification report\n",
    "report = classification_report(test__labels, y_pred_classes)\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'video_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'video_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Facultad\\PPS\\Proyecto Ecografia\\Build_Dense.ipynb Cell 14\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Facultad/PPS/Proyecto%20Ecografia/Build_Dense.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{\u001b[39;00mclass_vocab[i]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mprobabilities[i] \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m5.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Facultad/PPS/Proyecto%20Ecografia/Build_Dense.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m frames\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Facultad/PPS/Proyecto%20Ecografia/Build_Dense.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m test_video \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(test_df[\u001b[39m\"\u001b[39;49m\u001b[39mvideo_name\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Facultad/PPS/Proyecto%20Ecografia/Build_Dense.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest video path: \u001b[39m\u001b[39m{\u001b[39;00mtest_video\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Facultad/PPS/Proyecto%20Ecografia/Build_Dense.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m test_frames \u001b[39m=\u001b[39m sequence_prediction(test_video)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'video_name'"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
